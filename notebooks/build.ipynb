{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1J2odADxIxCT"
   },
   "source": [
    "# Predicting MLB Pitcher ERA from Climate and Performance Data\n",
    "\n",
    "Created by Jacob Sii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ssk6R1hsI7Dj"
   },
   "source": [
    "The inspiration for this project was an infographic of two elite MLB pitchers with highly fluccuating performance metrics correlated to the weather. I wanted to challenge the objectivity of this theory through EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JE1cxV28NOiX"
   },
   "source": [
    "#1. Power Analysis:\n",
    "This determines the minimum sample size needed to observe a meaningful relationship between weather and performance at a given confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QN1gTgRzNVNl",
    "outputId": "2b20e529-5143-4d70-8c10-4e1769a8e824"
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import FTestPowerF2\n",
    "power_analysis = FTestPowerF2()\n",
    "\n",
    "features = 8 # K/9, WHIP, FIP, IP, Temperature, Humidity, Wind Speed, Elevation\n",
    "sample_size = power_analysis.solve_power(effect_size=0.2, df_num=features, alpha=0.05, power=0.80)\n",
    "print(f\"A model with {features} predictive features should include at least {sample_size} observations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XMNp67GUWQj"
   },
   "source": [
    "#2. Pitcher Stats Extraction\n",
    "This portion of the notebook extracts per-game pitching statistics for all pitchers from 2022-2025. Statistics include strikeouts, base on balls, homeruns, hits allowed, earned runs, innings pitched, and batters hit by pitch. This raw data is used to compute our predictive features (ERA, K/9, WHIP, FIP).\n",
    "\n",
    "- ERA = (earned runs / IP) × 9\n",
    "- K/9 = (strikeouts / IP) × 9\n",
    "- WHIP = (walks + hits) / IP\n",
    "- FIP = ((13 × HR) + (3 × (BB + HBP)) − (2 × K)) / IP + 3.17\n",
    "\n",
    "The FIP constant (≈3.17) scales FIP onto the same range as ERA. Games where the pitcher recorded 0 outs are excluded since per-inning rates are undefined.\n",
    "\n",
    "We verify that our computed stats fall within expected MLB ranges:\n",
    "\n",
    "- ERA: Typically 0–27 for a single game (27 = 1 earned run per out)\n",
    "- K/9: Usually 0–27 (max ~4 K per inning for extra-out situations)\n",
    "- WHIP: Usually 0–10 for a single appearance\n",
    "- FIP: Generally -1 to 15 for individual games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mWTMOABEfoCj",
    "outputId": "df951e28-7323-4d49-efd8-013c7d64aa6b"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "extract_from_mlbapi.py\n",
    "\n",
    "Extracts per-game pitching stats for all MLB pitchers from 2021-2025.\n",
    "Computes: ERA, K/9, WHIP, FIP, IP (per game appearance).\n",
    "Outputs a CSV with one row per pitcher-game, including venue metadata\n",
    "for downstream weather data joins.\n",
    "\n",
    "FIP formula: ((13*HR) + (3*(BB+HBP)) - (2*K)) / IP + cFIP\n",
    "cFIP ≈ 3.17 (approximate league constant; stable across seasons at ~3.1-3.2)\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# ── Configuration ──────────────────────────────────────────────────────────────\n",
    "SEASONS = range(2022, 2026)          # 2022-2025\n",
    "SPORT_ID = 1                         # MLB\n",
    "MAX_WORKERS = 10                     # concurrent API requests\n",
    "FIP_CONSTANT = 3.17                  # approximate league constant (~3.1-3.2)\n",
    "OUTPUT_FILE = \"pitcher_game_stats_2021_2025.csv\"\n",
    "\n",
    "# ── HTTP Session ───────────────────────────────────────────────────────────────\n",
    "SESSION = requests.Session()\n",
    "SESSION.headers.update({\"User-Agent\": \"pitcher-climate-study/1.0\"})\n",
    "TIMEOUT = 20\n",
    "\n",
    "\n",
    "def api_get(url, retries=3, backoff=0.5):\n",
    "    \"\"\"GET request with exponential backoff retry.\"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            resp = SESSION.get(url, timeout=TIMEOUT)\n",
    "            if resp.ok:\n",
    "                return resp.json()\n",
    "        except requests.RequestException:\n",
    "            pass\n",
    "        time.sleep(backoff * (2 ** attempt))\n",
    "    return {}\n",
    "\n",
    "\n",
    "# ── Team & Roster Helpers ──────────────────────────────────────────────────────\n",
    "\n",
    "def get_team_ids(season):\n",
    "    \"\"\"Return list of MLB team IDs for a given season.\"\"\"\n",
    "    url = f\"https://statsapi.mlb.com/api/v1/teams?sportId={SPORT_ID}&season={season}\"\n",
    "    return [t[\"id\"] for t in api_get(url).get(\"teams\", [])]\n",
    "\n",
    "\n",
    "def get_pitcher_ids_for_season(season):\n",
    "    \"\"\"\n",
    "    Return set of pitcher person IDs who appeared on any MLB roster\n",
    "    in the given season. Uses the 40-man roster to capture pitchers\n",
    "    who were active at any point during the season.\n",
    "    \"\"\"\n",
    "    pitcher_ids = set()\n",
    "    for team_id in get_team_ids(season):\n",
    "        url = (\n",
    "            f\"https://statsapi.mlb.com/api/v1/teams/{team_id}/roster\"\n",
    "            f\"?rosterType=fullSeason&season={season}\"\n",
    "        )\n",
    "        roster = api_get(url).get(\"roster\", [])\n",
    "        for player in roster:\n",
    "            pos = player.get(\"position\", {}).get(\"abbreviation\", \"\")\n",
    "            if pos == \"P\":\n",
    "                pitcher_ids.add(player[\"person\"][\"id\"])\n",
    "    return pitcher_ids\n",
    "\n",
    "\n",
    "def get_all_pitcher_ids():\n",
    "    \"\"\"Collect unique pitcher IDs across all seasons.\"\"\"\n",
    "    all_ids = set()\n",
    "    for season in SEASONS:\n",
    "        print(f\"  Fetching rosters for {season}...\")\n",
    "        all_ids |= get_pitcher_ids_for_season(season)\n",
    "    print(f\"  Found {len(all_ids)} unique pitchers across {len(list(SEASONS))} seasons\")\n",
    "    return sorted(all_ids)\n",
    "\n",
    "\n",
    "# ── Schedule / Venue Map ──────────────────────────────────────────────────────\n",
    "\n",
    "def build_schedule_map(season):\n",
    "    \"\"\"\n",
    "    Build lookup: gamePk -> (venue_id, venue_name, city, state, game_date_utc, latitude, longitude)\n",
    "    Hydrates venue location for coordinate data (useful for weather API joins).\n",
    "    \"\"\"\n",
    "    url = (\n",
    "        f\"https://statsapi.mlb.com/api/v1/schedule\"\n",
    "        f\"?sportId={SPORT_ID}&season={season}\"\n",
    "        f\"&gameType=R,F,D,L,W\"\n",
    "        f\"&hydrate=venue(location)\"\n",
    "    )\n",
    "    data = api_get(url)\n",
    "    mapping = {}\n",
    "    for date_entry in data.get(\"dates\", []):\n",
    "        for game in date_entry.get(\"games\", []):\n",
    "            game_pk = game.get(\"gamePk\")\n",
    "            if not game_pk:\n",
    "                continue\n",
    "            venue = game.get(\"venue\") or {}\n",
    "            location = venue.get(\"location\") or {}\n",
    "            coords = location.get(\"defaultCoordinates\") or {}\n",
    "            mapping[game_pk] = {\n",
    "                \"venue_id\": venue.get(\"id\"),\n",
    "                \"venue_name\": venue.get(\"name\"),\n",
    "                \"city\": location.get(\"city\", \"\"),\n",
    "                \"state\": location.get(\"stateAbbrev\") or location.get(\"state\", \"\"),\n",
    "                \"game_date_utc\": game.get(\"gameDate\"),\n",
    "                \"latitude\": coords.get(\"latitude\"),\n",
    "                \"longitude\": coords.get(\"longitude\"),\n",
    "            }\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def build_all_schedule_maps():\n",
    "    \"\"\"Pre-build schedule maps for all seasons.\"\"\"\n",
    "    maps = {}\n",
    "    for season in SEASONS:\n",
    "        print(f\"  Building schedule map for {season}...\")\n",
    "        maps[season] = build_schedule_map(season)\n",
    "    return maps\n",
    "\n",
    "\n",
    "# ── Player Name Cache ─────────────────────────────────────────────────────────\n",
    "\n",
    "NAME_CACHE = {}\n",
    "\n",
    "def get_pitcher_name(person_id):\n",
    "    \"\"\"Fetch and cache a pitcher's full name.\"\"\"\n",
    "    if person_id in NAME_CACHE:\n",
    "        return NAME_CACHE[person_id]\n",
    "    url = f\"https://statsapi.mlb.com/api/v1/people/{person_id}\"\n",
    "    people = api_get(url).get(\"people\", [])\n",
    "    name = people[0][\"fullName\"] if people else str(person_id)\n",
    "    NAME_CACHE[person_id] = name\n",
    "    return name\n",
    "\n",
    "\n",
    "# ── Stat Computation ──────────────────────────────────────────────────────────\n",
    "\n",
    "def parse_ip(ip_str):\n",
    "    \"\"\"\n",
    "    Convert MLB innings pitched string to float.\n",
    "    MLB uses .1 = 1/3 inning, .2 = 2/3 inning.\n",
    "    e.g. '6.2' -> 6.667\n",
    "    \"\"\"\n",
    "    if not ip_str:\n",
    "        return 0.0\n",
    "    parts = str(ip_str).split(\".\")\n",
    "    whole = int(parts[0])\n",
    "    thirds = int(parts[1]) if len(parts) > 1 else 0\n",
    "    return whole + (thirds / 3.0)\n",
    "\n",
    "\n",
    "def compute_game_stats(stat_dict, ip_float):\n",
    "    \"\"\"\n",
    "    Compute per-game pitching metrics from raw API stat fields.\n",
    "\n",
    "    Returns dict with: ip, era, k_per_9, whip, fip\n",
    "    \"\"\"\n",
    "    # Raw counts from API\n",
    "    earned_runs = stat_dict.get(\"earnedRuns\", 0)\n",
    "    strikeouts = stat_dict.get(\"strikeOuts\", 0)\n",
    "    walks = stat_dict.get(\"baseOnBalls\", 0)\n",
    "    hits = stat_dict.get(\"hits\", 0)\n",
    "    home_runs = stat_dict.get(\"homeRuns\", 0)\n",
    "    hbp = stat_dict.get(\"hitBatsmen\", 0)\n",
    "\n",
    "    # ERA = (earned runs / IP) * 9\n",
    "    era = (earned_runs * 9.0) / ip_float\n",
    "\n",
    "    # K/9 = (strikeouts / IP) * 9\n",
    "    k_per_9 = (strikeouts * 9.0) / ip_float\n",
    "\n",
    "    # WHIP = (walks + hits) / IP\n",
    "    whip = (walks + hits) / ip_float\n",
    "\n",
    "    # FIP = ((13*HR) + (3*(BB+HBP)) - (2*K)) / IP + cFIP\n",
    "    fip = ((13 * home_runs) + (3 * (walks + hbp)) - (2 * strikeouts)) / ip_float + FIP_CONSTANT\n",
    "\n",
    "    return {\n",
    "        \"ip\": round(ip_float, 3),\n",
    "        \"earned_runs\": earned_runs,\n",
    "        \"strikeouts\": strikeouts,\n",
    "        \"walks\": walks,\n",
    "        \"hits_allowed\": hits,\n",
    "        \"home_runs_allowed\": home_runs,\n",
    "        \"hit_by_pitch\": hbp,\n",
    "        \"era\": round(era, 3),\n",
    "        \"k_per_9\": round(k_per_9, 3),\n",
    "        \"whip\": round(whip, 3),\n",
    "        \"fip\": round(fip, 3),\n",
    "    }\n",
    "\n",
    "\n",
    "# ── Per-Pitcher Extraction ────────────────────────────────────────────────────\n",
    "\n",
    "def extract_pitcher_games(pitcher_id, schedule_maps):\n",
    "    \"\"\"\n",
    "    Pull game logs for one pitcher across all seasons.\n",
    "    Returns list of row dicts.\n",
    "    \"\"\"\n",
    "    name = get_pitcher_name(pitcher_id)\n",
    "    rows = []\n",
    "\n",
    "    for season in SEASONS:\n",
    "        url = (\n",
    "            f\"https://statsapi.mlb.com/api/v1/people/{pitcher_id}/stats\"\n",
    "            f\"?stats=gameLog&group=pitching&season={season}\"\n",
    "        )\n",
    "        data = api_get(url).get(\"stats\", [])\n",
    "        splits = data[0].get(\"splits\", []) if data else []\n",
    "        sched = schedule_maps[season]\n",
    "\n",
    "        for split in splits:\n",
    "            stat = split.get(\"stat\", {})\n",
    "            ip_float = parse_ip(stat.get(\"inningsPitched\", \"0\"))\n",
    "\n",
    "            # Skip appearances with 0 IP (no outs recorded)\n",
    "            if ip_float == 0:\n",
    "                continue\n",
    "\n",
    "            game_pk = (split.get(\"game\") or {}).get(\"gamePk\")\n",
    "            if not game_pk:\n",
    "                continue\n",
    "\n",
    "            venue_info = sched.get(game_pk, {})\n",
    "            if not venue_info.get(\"venue_name\") or not venue_info.get(\"game_date_utc\"):\n",
    "                continue\n",
    "\n",
    "            # Compute all stats\n",
    "            stats = compute_game_stats(stat, ip_float)\n",
    "\n",
    "            rows.append({\n",
    "                \"pitcher_id\": pitcher_id,\n",
    "                \"pitcher_name\": name,\n",
    "                \"season\": season,\n",
    "                \"game_pk\": game_pk,\n",
    "                \"game_date_utc\": venue_info[\"game_date_utc\"],\n",
    "                \"venue_name\": venue_info[\"venue_name\"],\n",
    "                \"venue_city\": venue_info[\"city\"],\n",
    "                \"venue_state\": venue_info[\"state\"],\n",
    "                \"latitude\": venue_info.get(\"latitude\"),\n",
    "                \"longitude\": venue_info.get(\"longitude\"),\n",
    "                **stats,\n",
    "            })\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ── Main ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"MLB Pitcher Game Stats Extraction (2021-2025)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Step 1: Build schedule maps (venue + location data)\n",
    "    print(\"\\n[1/3] Building season schedule maps...\")\n",
    "    schedule_maps = build_all_schedule_maps()\n",
    "\n",
    "    # Step 2: Collect all pitcher IDs\n",
    "    print(\"\\n[2/3] Collecting pitcher IDs from rosters...\")\n",
    "    pitcher_ids = get_all_pitcher_ids()\n",
    "\n",
    "    # Step 3: Extract game logs concurrently\n",
    "    print(f\"\\n[3/3] Extracting game logs for {len(pitcher_ids)} pitchers...\")\n",
    "    all_rows = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = {\n",
    "            executor.submit(extract_pitcher_games, pid, schedule_maps): pid\n",
    "            for pid in pitcher_ids\n",
    "        }\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Pitchers\"):\n",
    "            try:\n",
    "                all_rows.extend(future.result())\n",
    "            except Exception as e:\n",
    "                pid = futures[future]\n",
    "                print(f\"\\n  Warning: failed for pitcher {pid}: {e}\")\n",
    "\n",
    "    # Build DataFrame and save\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    df = df.sort_values([\"pitcher_name\", \"game_date_utc\"]).reset_index(drop=True)\n",
    "    df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Done! Saved to {OUTPUT_FILE}\")\n",
    "    print(f\"  Rows:     {len(df):,}\")\n",
    "    print(f\"  Pitchers: {df['pitcher_id'].nunique():,}\")\n",
    "    print(f\"  Seasons:  {sorted(df['season'].unique())}\")\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    print(f\"\\nSample:\\n{df.head()}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nG-zA3mmhj0g"
   },
   "source": [
    "#3. Weather Data Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNnsG3jGhrU6",
    "outputId": "1bf3eca9-ce22-4cf2-9726-f2920287972a"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "extract_weather_data.py\n",
    "\n",
    "Pulls historical weather data from the Open-Meteo Archive API for each\n",
    "unique game location + date in the pitcher stats dataset.\n",
    "\n",
    "Climate features extracted (aligned with power analysis):\n",
    "    - temperature (°F at game time)\n",
    "    - humidity (% at game time)\n",
    "    - wind_speed (mph at game time)\n",
    "    - elevation (ft above sea level, per venue)\n",
    "\n",
    "Approach:\n",
    "    - Deduplicate games by (game_pk, latitude, longitude, game_date)\n",
    "      so we only make one API call per unique venue-date combination\n",
    "    - Pull hourly weather for each game date\n",
    "    - Select the hour closest to typical first pitch (~7 PM local)\n",
    "    - Merge weather back onto every pitcher appearance for that game\n",
    "\n",
    "Outputs: weather_by_game.csv (one row per unique game)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ── Configuration ──────────────────────────────────────────────────────────────\n",
    "PITCHER_STATS_FILE = \"pitcher_game_stats_2021_2025.csv\"\n",
    "OUTPUT_FILE = \"weather_by_game.csv\"\n",
    "OPEN_METEO_URL = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "# Weather variables to request (order matters for parsing)\n",
    "HOURLY_VARIABLES = [\n",
    "    \"temperature_2m\",          # °C -> convert to °F\n",
    "    \"relative_humidity_2m\",    # %\n",
    "    \"wind_speed_10m\",          # km/h -> convert to mph\n",
    "]\n",
    "\n",
    "# Typical MLB first pitch hour in UTC\n",
    "# Most games start 7 PM ET = 23:00 UTC (night) or 1 PM ET = 17:00 UTC (day)\n",
    "# We'll pick the closest hour to the actual game time from the data\n",
    "DEFAULT_GAME_HOUR_UTC = 23\n",
    "\n",
    "# Unit conversions\n",
    "C_TO_F = lambda c: (c * 9 / 5) + 32\n",
    "KMH_TO_MPH = lambda k: k * 0.621371\n",
    "M_TO_FT = lambda m: m * 3.28084\n",
    "\n",
    "# Rate limiting: Open-Meteo free tier allows ~10,000 calls/day\n",
    "REQUEST_DELAY = 0.25  # seconds between requests\n",
    "\n",
    "# ── HTTP Session ───────────────────────────────────────────────────────────────\n",
    "SESSION = requests.Session()\n",
    "SESSION.headers.update({\"User-Agent\": \"pitcher-climate-study/1.0\"})\n",
    "\n",
    "\n",
    "def api_get(url, params, retries=3, backoff=1.0):\n",
    "    \"\"\"GET with retry and backoff.\"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            resp = SESSION.get(url, params=params, timeout=30)\n",
    "            if resp.ok:\n",
    "                return resp.json()\n",
    "            elif resp.status_code == 429:\n",
    "                # Rate limited — wait longer\n",
    "                time.sleep(backoff * (2 ** attempt) * 5)\n",
    "            else:\n",
    "                resp.raise_for_status()\n",
    "        except requests.RequestException as e:\n",
    "            if attempt == retries - 1:\n",
    "                print(f\"  Failed after {retries} retries: {e}\")\n",
    "            time.sleep(backoff * (2 ** attempt))\n",
    "    return None\n",
    "\n",
    "\n",
    "# ── Game Deduplication ─────────────────────────────────────────────────────────\n",
    "\n",
    "def get_unique_games(df):\n",
    "    \"\"\"\n",
    "    Extract unique game-venue-date combinations from pitcher stats.\n",
    "    This avoids redundant API calls — if 10 pitchers appeared in the\n",
    "    same game, we only need weather data once for that game.\n",
    "    \"\"\"\n",
    "    # Parse game date (just the date portion, not full datetime)\n",
    "    df = df.copy()\n",
    "    df[\"game_date\"] = pd.to_datetime(df[\"game_date_utc\"]).dt.date\n",
    "    df[\"game_hour_utc\"] = pd.to_datetime(df[\"game_date_utc\"]).dt.hour\n",
    "\n",
    "    games = (\n",
    "        df.groupby(\"game_pk\")\n",
    "        .agg({\n",
    "            \"game_date\": \"first\",\n",
    "            \"game_hour_utc\": \"first\",\n",
    "            \"venue_name\": \"first\",\n",
    "            \"venue_city\": \"first\",\n",
    "            \"venue_state\": \"first\",\n",
    "            \"latitude\": \"first\",\n",
    "            \"longitude\": \"first\",\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Drop games missing coordinates\n",
    "    before = len(games)\n",
    "    games = games.dropna(subset=[\"latitude\", \"longitude\"])\n",
    "    dropped = before - len(games)\n",
    "    if dropped > 0:\n",
    "        print(f\"  Dropped {dropped} games with missing coordinates\")\n",
    "\n",
    "    print(f\"  {len(games)} unique games to fetch weather for\")\n",
    "    return games\n",
    "\n",
    "\n",
    "# ── Weather Fetching ───────────────────────────────────────────────────────────\n",
    "\n",
    "def fetch_game_weather(lat, lon, game_date, game_hour_utc=None):\n",
    "    \"\"\"\n",
    "    Fetch hourly weather for a single location and date from Open-Meteo.\n",
    "    Returns dict with weather values at the hour closest to game time,\n",
    "    plus elevation.\n",
    "\n",
    "    Returns None on failure.\n",
    "    \"\"\"\n",
    "    date_str = str(game_date)\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": date_str,\n",
    "        \"end_date\": date_str,\n",
    "        \"hourly\": \",\".join(HOURLY_VARIABLES),\n",
    "        \"temperature_unit\": \"celsius\",\n",
    "        \"wind_speed_unit\": \"kmh\",\n",
    "    }\n",
    "\n",
    "    data = api_get(OPEN_METEO_URL, params)\n",
    "    if not data or \"hourly\" not in data:\n",
    "        return None\n",
    "\n",
    "    hourly = data[\"hourly\"]\n",
    "    times = hourly.get(\"time\", [])\n",
    "    if not times:\n",
    "        return None\n",
    "\n",
    "    # Determine which hour to use\n",
    "    target_hour = game_hour_utc if game_hour_utc else DEFAULT_GAME_HOUR_UTC\n",
    "\n",
    "    # Find the index of the closest hour\n",
    "    hours = [int(t.split(\"T\")[1].split(\":\")[0]) for t in times]\n",
    "    best_idx = min(range(len(hours)), key=lambda i: abs(hours[i] - target_hour))\n",
    "\n",
    "    # Extract values at game time\n",
    "    temp_c = hourly.get(\"temperature_2m\", [None])[best_idx]\n",
    "    humidity = hourly.get(\"relative_humidity_2m\", [None])[best_idx]\n",
    "    wind_kmh = hourly.get(\"wind_speed_10m\", [None])[best_idx]\n",
    "\n",
    "    # Elevation comes from the top-level response (meters)\n",
    "    elevation_m = data.get(\"elevation\")\n",
    "\n",
    "    # Convert units\n",
    "    result = {\n",
    "        \"temperature_f\": round(C_TO_F(temp_c), 1) if temp_c is not None else None,\n",
    "        \"humidity_pct\": humidity,\n",
    "        \"wind_speed_mph\": round(KMH_TO_MPH(wind_kmh), 1) if wind_kmh is not None else None,\n",
    "        \"elevation_ft\": round(M_TO_FT(elevation_m), 1) if elevation_m is not None else None,\n",
    "        \"weather_hour_utc\": hours[best_idx],\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def fetch_all_game_weather(games_df):\n",
    "    \"\"\"\n",
    "    Fetch weather for all unique games. Returns DataFrame with weather columns.\n",
    "    \"\"\"\n",
    "    weather_rows = []\n",
    "\n",
    "    for _, game in tqdm(games_df.iterrows(), total=len(games_df), desc=\"Fetching weather\"):\n",
    "        weather = fetch_game_weather(\n",
    "            lat=game[\"latitude\"],\n",
    "            lon=game[\"longitude\"],\n",
    "            game_date=game[\"game_date\"],\n",
    "            game_hour_utc=game.get(\"game_hour_utc\"),\n",
    "        )\n",
    "\n",
    "        row = {\"game_pk\": game[\"game_pk\"]}\n",
    "\n",
    "        if weather:\n",
    "            row.update(weather)\n",
    "        else:\n",
    "            row.update({\n",
    "                \"temperature_f\": None,\n",
    "                \"humidity_pct\": None,\n",
    "                \"wind_speed_mph\": None,\n",
    "                \"elevation_ft\": None,\n",
    "                \"weather_hour_utc\": None,\n",
    "            })\n",
    "\n",
    "        weather_rows.append(row)\n",
    "\n",
    "        # Rate limiting\n",
    "        time.sleep(REQUEST_DELAY)\n",
    "\n",
    "    return pd.DataFrame(weather_rows)\n",
    "\n",
    "\n",
    "# ── Main ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Weather Data Extraction for Pitcher-Climate Study\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Step 1: Load pitcher stats\n",
    "    print(\"\\n[1/4] Loading pitcher game stats...\")\n",
    "    pitcher_df = pd.read_csv(PITCHER_STATS_FILE)\n",
    "    print(f\"  {len(pitcher_df):,} pitcher appearances loaded\")\n",
    "\n",
    "    # Step 2: Deduplicate to unique games\n",
    "    print(\"\\n[2/4] Identifying unique games...\")\n",
    "    games = get_unique_games(pitcher_df)\n",
    "\n",
    "    # Step 3: Fetch weather for each game\n",
    "    print(\"\\n[3/4] Fetching weather data from Open-Meteo...\")\n",
    "    weather_df = fetch_all_game_weather(games)\n",
    "\n",
    "    # Step 4: Save and report\n",
    "    print(\"\\n[4/4] Saving results...\")\n",
    "    weather_df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "    # Summary stats\n",
    "    total = len(weather_df)\n",
    "    complete = weather_df.dropna(subset=[\"temperature_f\"]).shape[0]\n",
    "    missing = total - complete\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Done! Saved to {OUTPUT_FILE}\")\n",
    "    print(f\"  Total games:   {total:,}\")\n",
    "    print(f\"  With weather:  {complete:,}\")\n",
    "    print(f\"  Missing:       {missing:,}\")\n",
    "    print(f\"\\nWeather summary:\")\n",
    "    print(weather_df[[\"temperature_f\", \"humidity_pct\", \"wind_speed_mph\", \"elevation_ft\"]].describe())\n",
    "\n",
    "    return weather_df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    weather_df = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P13M1inj7tkg"
   },
   "source": [
    "#4. Clean and Unify Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyigsCEN79aq"
   },
   "source": [
    "Merge the data by pairing weather data with the park each game was played at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E0uUNLus8ZrV",
    "outputId": "528a0ce3-87e0-4c76-ca18-04d128651411"
   },
   "outputs": [],
   "source": [
    "pitcher_data = pd.read_csv('pitcher_game_stats_2021_2025.csv')\n",
    "weather_data = pd.read_csv('weather_by_game.csv')\n",
    "complete_data = pitcher_data.merge(weather_data, on='game_pk', how='left')\n",
    "\n",
    "print(f\"Rows: {len(complete_data)}\")\n",
    "print(f\"Null weather rows: {complete_data['temperature_f'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zx8qnHSH_Itr"
   },
   "source": [
    "Drop rows where weather data is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "up0rhJ92_MJl",
    "outputId": "0ce03502-9d30-4353-8a30-3ab0f49d5ebd"
   },
   "outputs": [],
   "source": [
    "complete_data = complete_data.dropna(subset=['temperature_f', 'humidity_pct', 'wind_speed_mph', 'elevation_ft'])\n",
    "\n",
    "print(f\"Rows: {len(complete_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Z2uPR5_AgiQ"
   },
   "source": [
    "Save this as the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtrOBariAtdM"
   },
   "outputs": [],
   "source": [
    "complete_data.to_csv('pitcher_climate_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8qPAMfGBbmM"
   },
   "source": [
    "#5. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc7aUcGKL291"
   },
   "source": [
    "We start by verifying the datasets merged properly, explore the distributions of our features, and look for relationships between climate data and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "b_Bio_8ULsLh",
    "outputId": "1cd734ad-f062-4cbb-98b3-48de5cf68adc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "df = pd.read_csv(\"pitcher_climate_merged.csv\")\n",
    "print(f\"Dataset: {len(df):,} rows × {df.shape[1]} columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LTSHcntMUqu"
   },
   "source": [
    "Lets first check for missing values, establish data types, and get a summary of statistics. This way we catch games that were missing weather data or extreme stat lines from extremely short outings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zs8oVScNNVQM",
    "outputId": "b6dd8fdc-f7a8-493a-8bac-b4aa71bebcc6"
   },
   "outputs": [],
   "source": [
    "print(\"Data types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nNull counts:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "\n",
    "# Key columns to inspect\n",
    "stat_cols = [\"era\", \"k_per_9\", \"whip\", \"fip\", \"ip\", \"temperature_f\", \"humidity_pct\", \"wind_speed_mph\", \"elevation_ft\"]\n",
    "\n",
    "df[stat_cols].describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbNFQptKNplX"
   },
   "source": [
    "Pitcher outings where few outs were recorded produce extreme per-game ratio stats. i.e. A reliever allows 2 earned runs and gets pulled after recording only 1 out (0.1 IP) has an ERA of 54.00 for that game. The calcualtion is correct but this is not meaningful for our model. We will filter to games with at least 3.0 IP to emphasize games with enough data maintain stable ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lMUdfe4qOmVM",
    "outputId": "4850e64a-d124-4e82-8c99-b75ce6e96d61"
   },
   "outputs": [],
   "source": [
    "print(f\"Before filter: {len(df):,} rows\")\n",
    "print(f\"IP distribution (pre-filter):\")\n",
    "print(df[\"ip\"].describe().round(2))\n",
    "\n",
    "df = df[df[\"ip\"] >= 3.0].copy()\n",
    "\n",
    "print(f\"\\nAfter filter (IP >= 3.0): {len(df):,} rows\")\n",
    "print(f\"ERA range after filter: {df['era'].min():.2f} – {df['era'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DHPFfuWO8kp"
   },
   "source": [
    "Now lets plot the distributions of our prediction target (ERA) and the predictor features to understand their shape and spot any outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "QSfn2zmgPa0I",
    "outputId": "90fcb7a9-253f-49aa-9700-bc3a6ef896ae"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# ERA histogram\n",
    "axes[0].hist(df[\"era\"], bins=50, edgecolor=\"black\", alpha=0.7, color=\"steelblue\")\n",
    "axes[0].axvline(df[\"era\"].mean(), color=\"red\", linestyle=\"--\", label=f'Mean: {df[\"era\"].mean():.2f}')\n",
    "axes[0].axvline(df[\"era\"].median(), color=\"orange\", linestyle=\"--\", label=f'Median: {df[\"era\"].median():.2f}')\n",
    "axes[0].set_title(\"Distribution of Game ERA (Target)\")\n",
    "axes[0].set_xlabel(\"ERA\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "axes[0].legend()\n",
    "\n",
    "# ERA box plot\n",
    "axes[1].boxplot(df[\"era\"], vert=True)\n",
    "axes[1].set_title(\"Game ERA Box Plot\")\n",
    "axes[1].set_ylabel(\"ERA\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"ERA skewness: {df['era'].skew():.2f}\")\n",
    "print(f\"ERA kurtosis: {df['era'].kurtosis():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lp8m0Tg1PirF"
   },
   "source": [
    "We see that ERA is skewed right but this is expected as most pitchers fall in the 0 to 6 ERA range. The skew is not enough to require a tranformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "Y-IAIEC0P3-e",
    "outputId": "2a5ff076-9319-4005-d206-61faa64ddd3f"
   },
   "outputs": [],
   "source": [
    "pitching_features = [\"k_per_9\", \"whip\", \"fip\", \"ip\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "for ax, col in zip(axes, pitching_features):\n",
    "    ax.hist(df[col], bins=40, edgecolor=\"black\", alpha=0.7, color=\"steelblue\")\n",
    "    ax.axvline(df[col].mean(), color=\"red\", linestyle=\"--\", alpha=0.7)\n",
    "    ax.set_title(col.upper().replace(\"_\", \"/\"))\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "fig.suptitle(\"Pitching Feature Distributions\", y=1.02, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "X7GmUlHdQKs1",
    "outputId": "e10c6218-0484-4366-a5f7-ce5a952e37ef"
   },
   "outputs": [],
   "source": [
    "climate_features = [\"temperature_f\", \"humidity_pct\", \"wind_speed_mph\", \"elevation_ft\"]\n",
    "climate_labels = [\"Temperature (°F)\", \"Humidity (%)\", \"Wind Speed (mph)\", \"Elevation (ft)\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "for ax, col, label in zip(axes, climate_features, climate_labels):\n",
    "    ax.hist(df[col], bins=40, edgecolor=\"black\", alpha=0.7, color=\"coral\")\n",
    "    ax.axvline(df[col].mean(), color=\"red\", linestyle=\"--\", alpha=0.7)\n",
    "    ax.set_title(label)\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "fig.suptitle(\"Climate Feature Distributions\", y=1.02, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsc9MWzCQS-c"
   },
   "source": [
    "- Temperature: normal distribution centered around 75°F which is standard for April-October\n",
    "- Humidity: roughly normal and centered around 60% humidity\n",
    "- Wind speed: right-skewed as most games have moderate wind conditions\n",
    "- Elevation: clustered with most observations near sea level but outlier around 5,000 ft for Coors Field in Denver, CO. There is very little variance here but it accurately represents the effect elevation has on ball flight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xh39GqoVSHqu"
   },
   "source": [
    "Now we search for any indicators of a relationship between the climate and performance. We will use scatter plots with trend lines and binned averages to search for patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "7yNcnpDNS11-",
    "outputId": "f6d6d403-53d5-42e2-dcec-4e317393430d"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "for ax, col, label in zip(axes, climate_features, climate_labels):\n",
    "    # Sample for cleaner scatter (full dataset is dense)\n",
    "    sample = df.sample(min(3000, len(df)), random_state=42)\n",
    "    ax.scatter(sample[col], sample[\"era\"], alpha=0.1, s=10, color=\"steelblue\")\n",
    "\n",
    "    # Trend line\n",
    "    z = np.polyfit(df[col].dropna(), df.loc[df[col].notna(), \"era\"], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_range = np.linspace(df[col].min(), df[col].max(), 100)\n",
    "    ax.plot(x_range, p(x_range), color=\"red\", linewidth=2)\n",
    "\n",
    "    ax.set_xlabel(label)\n",
    "    ax.set_ylabel(\"ERA\" if col == climate_features[0] else \"\")\n",
    "    ax.set_ylim(0, 15)\n",
    "\n",
    "fig.suptitle(\"Game ERA vs. Climate Features\", y=1.02, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLtrqe0aTZG8"
   },
   "source": [
    "The scatter plots appear noisy due to the volume and fluccuations of individual game performances. The trend lines give us hints at the direction of the relationships. We'll get a better look at the patterns by binning each climate feature into quantiles and compare the mean ERA across the bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "QyIJIoVrT24n",
    "outputId": "3f7648cd-62d5-4d89-a8e5-88b4485e0a5e"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "for ax, col, label in zip(axes, climate_features, climate_labels):\n",
    "    # Create 8 bins based on quantiles\n",
    "    df[\"_bin\"] = pd.qcut(df[col], q=8, duplicates=\"drop\")\n",
    "    binned = df.groupby(\"_bin\", observed=True)[\"era\"].agg([\"mean\", \"sem\"]).reset_index()\n",
    "\n",
    "    # Plot with error bars\n",
    "    x_pos = range(len(binned))\n",
    "    ax.bar(x_pos, binned[\"mean\"], yerr=binned[\"sem\"],\n",
    "           color=\"coral\", edgecolor=\"black\", alpha=0.7, capsize=3)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels([str(b) for b in binned[\"_bin\"]], rotation=45, ha=\"right\", fontsize=6)\n",
    "    ax.set_ylabel(\"Mean ERA\" if col == climate_features[0] else \"\")\n",
    "    ax.set_title(label)\n",
    "\n",
    "df.drop(columns=[\"_bin\"], inplace=True)\n",
    "\n",
    "fig.suptitle(\"Mean ERA by Climate Feature (Binned)\", y=1.02, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SR8Pzo24T9At"
   },
   "source": [
    "The binned analysis gives a more clear view of the the relationships. The error bars, which represent standard error of the mean, show more meaning when the bars do not overlap between bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 844
    },
    "id": "ywtZCJ9SVKlU",
    "outputId": "8140414e-5f9f-4757-8683-fec003573dbf"
   },
   "outputs": [],
   "source": [
    "corr_cols = [\"era\", \"k_per_9\", \"whip\", \"fip\", \"ip\",\n",
    "             \"temperature_f\", \"humidity_pct\", \"wind_speed_mph\", \"elevation_ft\"]\n",
    "\n",
    "corr_matrix = df[corr_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 7))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    mask=mask,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"RdBu_r\",\n",
    "    center=0,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_title(\"Feature Correlation Matrix\", fontsize=14, pad=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7s-GI96VqT8"
   },
   "source": [
    "Key Takeways:\n",
    "\n",
    "Pitching:\n",
    "- ERA and FIP are positively correlated as expected considering an increase in either implies poor pitching performance. We will include both as FIP isolates the pitchers actions while ERA is the actual outcome.\n",
    "- K/9 is negatively correlated with ERA because more strikeout leads to less runs scored.\n",
    "- WHIP is positively correlated with ERA because more baserunners increase the likelyhood somebody will score.\n",
    "\n",
    "Climate:\n",
    "- Climate features have little to know correlation with eachother which is a good sign for maintaining independence.\n",
    "- The correlation between climate and ERA are small. Weather affects pitching minimally according to this matrix but we will measure their value based on how they affect they improve the model compared to a pitching stas only baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zgp9h9WY2bL"
   },
   "source": [
    "Coors Field (Denver, CO) is the highest elevated park by a large margin leading to offense inflation. Let's confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "jAcVP492YxnA",
    "outputId": "58286e90-aed8-4dfe-fa9d-47036fc6208a"
   },
   "outputs": [],
   "source": [
    "coors = df[df[\"elevation_ft\"] > 5000]\n",
    "non_coors = df[df[\"elevation_ft\"] <= 5000]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "ax.hist(non_coors[\"era\"], bins=50, alpha=0.6, color=\"steelblue\",\n",
    "        label=f'Other Parks (n={len(non_coors):,}, mean={non_coors[\"era\"].mean():.2f})',\n",
    "        density=True, edgecolor=\"black\")\n",
    "ax.hist(coors[\"era\"], bins=30, alpha=0.6, color=\"coral\",\n",
    "        label=f'Coors Field (n={len(coors):,}, mean={coors[\"era\"].mean():.2f})',\n",
    "        density=True, edgecolor=\"black\")\n",
    "\n",
    "ax.set_xlabel(\"Game ERA\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.set_title(\"ERA Distribution: Coors Field vs. All Other Parks\")\n",
    "ax.legend()\n",
    "ax.set_xlim(0, 15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical test\n",
    "from scipy import stats\n",
    "t_stat, p_val = stats.ttest_ind(coors[\"era\"], non_coors[\"era\"], equal_var=False)\n",
    "print(f\"Welch's t-test: t={t_stat:.3f}, p={p_val:.4f}\")\n",
    "print(f\"Coors mean ERA:     {coors['era'].mean():.3f}\")\n",
    "print(f\"Non-Coors mean ERA: {non_coors['era'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGhHOTmbZ4oX"
   },
   "source": [
    "This visualization confirms Coors Field inflates scoring confirming the elevation feature embodies the idea that thinner air redices pitch movement and allows the ball to carry farther."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "fEdodY4bZ6Ds",
    "outputId": "1c6c80d4-4c76-4035-92f2-09b1f0cd2ffe"
   },
   "outputs": [],
   "source": [
    "temp_bins = pd.cut(df[\"temperature_f\"], bins=[30, 50, 60, 70, 80, 90, 110],\n",
    "                   labels=[\"30-50\", \"50-60\", \"60-70\", \"70-80\", \"80-90\", \"90+\"])\n",
    "\n",
    "temp_summary = df.groupby(temp_bins, observed=True)[\"era\"].agg([\"mean\", \"sem\", \"count\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "bars = ax.bar(temp_summary.index, temp_summary[\"mean\"], yerr=temp_summary[\"sem\"],\n",
    "              color=\"coral\", edgecolor=\"black\", alpha=0.7, capsize=4)\n",
    "\n",
    "# Add sample size labels\n",
    "for bar, count in zip(bars, temp_summary[\"count\"]):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.05,\n",
    "            f'n={count:,}', ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "ax.set_xlabel(\"Temperature (°F)\")\n",
    "ax.set_ylabel(\"Mean ERA\")\n",
    "ax.set_title(\"Mean Pitcher ERA by Temperature Range\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykIDKrEybDsK"
   },
   "source": [
    "The temperature graphic clearly represents another physical behavior of warmer air being less dense affecting pitch movement and ball carry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rV88qjA3bfmC"
   },
   "source": [
    "## Summary:\n",
    "\n",
    "**Data Quality:**\n",
    "After filtering out games where the pitcher did not complete at least three innings and minimizing missing values we have a clean data set prepared for modeling.\n",
    "\n",
    "**Feature Distributions:**\n",
    "Pitching stats are distributed as predicted and climate features show reasonable variance for the baseball season months. Elevation is the least variable is known to have the largest affect on performance.\n",
    "\n",
    "**Climate Signals:**\n",
    "Climate features show small directional relationships with ERA. Elevation is the most signifacnt as shown by the Coors Park analysis. Temperature, humidity, and wind show weaker patterns.\n",
    "\n",
    "**Multicollinearity:**\n",
    "Climate features are mostly independent of eachother as demonstrated in the feature correlation matrix which is ideal for our regression model. Pitching features are correlated considering they are derived from the same raw statistics but represent different aspects of their performance.\n",
    "\n",
    "**Modeling Approach:**\n",
    "Considering the noise introduced by single-game performances we expect the model to be mostly influenced by pitcher stats with slight improvement from the climate features. We will quantify this by comparing an XGBoost model trained with pitching stats only to a model trained with pitching and climate features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUWbz4Jig88y"
   },
   "source": [
    "#6. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZFzRIzqhIEA"
   },
   "source": [
    "Giving the model information it would not have access to at prediction time is known as data leakage. This could lead to inaccurate measurements of accuracy. We can't use the pitchers stats from the current game to predict their ERA for the same game. To avoid this we will use rolling historical averages from all pitcher's prior performances.\n",
    "\n",
    "The model will have access to:\n",
    "- rolling_era - average ERA across all previous games\n",
    "- rolling_k_per_9 - historical strikeout rate\n",
    "- rolling_whip - historical walks + hits per inning\n",
    "- rolling_fip - historical fielding independent pitching\n",
    "- rolling_ip - average innings pitched per game\n",
    "\n",
    "We use shift(1) to excluse the current game and expanding.mean() to compute a cumulative average of all games in the data set. This leads to the rolling stats stabilizing as the season progresses and more games are added. Mid-season games will have much less noisy rolling statistics.\n",
    "\n",
    "Note: Each pitcher's first game is dropped due to no prior data to compute rolling stats on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZvbSQT3hEDQ",
    "outputId": "48341798-f80e-4707-9ec6-44439b08ae17"
   },
   "outputs": [],
   "source": [
    "# Sort chronologically per pitcher\n",
    "df = df.sort_values([\"pitcher_id\", \"game_date_utc\"]).reset_index(drop=True)\n",
    "\n",
    "# Rolling averages from PRIOR games (shift to prevent leakage)\n",
    "rolling_cols = [\"era\", \"k_per_9\", \"whip\", \"fip\", \"ip\"]\n",
    "for col in rolling_cols:\n",
    "    df[f\"rolling_{col}\"] = (\n",
    "        df.groupby(\"pitcher_id\")[col]\n",
    "        .transform(lambda x: x.shift(1).expanding().mean())\n",
    "    )\n",
    "\n",
    "# Drop rows where rolling stats are null (each pitcher's first appearance)\n",
    "df = df.dropna(subset=[f\"rolling_{col}\" for col in rolling_cols])\n",
    "print(f\"Rows after feature engineering: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFPQxFjjlroK"
   },
   "source": [
    "#7. Modeling: Do Climate Considerations Improve ERA Prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCwwZS1EmE30"
   },
   "source": [
    "To answer our original question we will train two XGBoost regression models and compare their performance.\n",
    "\n",
    "- **Model A (Baseline):** Rolling pitching stats only\n",
    "- **Model B (Climate):** Rolling pitching stats + game day weather\n",
    "\n",
    "This will allow us to test if the climate features improve the performance of the pitching stats prediction model. If Model B meaninfully outperforms Model A, the outcome suggests weather conditions carry influence over the pitcher's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1wPFe3dvnX1W",
    "outputId": "251c4c9b-ab0b-432e-875a-79edfdce6e4c"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define feature sets\n",
    "pitching_features = [\"rolling_era\", \"rolling_k_per_9\", \"rolling_whip\", \"rolling_fip\", \"rolling_ip\"]\n",
    "climate_features = [\"temperature_f\", \"humidity_pct\", \"wind_speed_mph\", \"elevation_ft\"]\n",
    "\n",
    "target = \"era\"\n",
    "\n",
    "# Model A: pitching only\n",
    "features_a = pitching_features\n",
    "\n",
    "# Model B: pitching + climate\n",
    "features_b = pitching_features + climate_features\n",
    "\n",
    "print(f\"Model A features ({len(features_a)}): {features_a}\")\n",
    "print(f\"Model B features ({len(features_b)}): {features_b}\")\n",
    "print(f\"Target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6orYKXOnda5"
   },
   "source": [
    "### Train / Test Split\n",
    "We will use an 80/20 split and shuffle the data to ensure both sets contain a mix of all seasons and weather conidtions. Models will use identical splits to maintain equality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fck6Q-kMoGqj",
    "outputId": "7c83db77-f56a-4784-8a7e-e06d77510b24"
   },
   "outputs": [],
   "source": [
    "# Drop rows with any nulls in our feature + target columns\n",
    "model_df = df[features_b + [target]].dropna()\n",
    "print(f\"Modeling dataset: {len(model_df):,} rows\")\n",
    "\n",
    "X = model_df[features_b]\n",
    "y = model_df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train):,} rows\")\n",
    "print(f\"Test:  {len(X_test):,} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kZKPGr6oLic"
   },
   "source": [
    "### Model Training\n",
    "\n",
    "We use XGBoost with mid level hyperparamters to start. Models will use identical setting so any differences can be attributed to the climate features being inlcuded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aQ23O25Kooaw",
    "outputId": "4dba8351-b64b-4604-ca91-abd4baa323a3"
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "# Model A: Pitching stats only\n",
    "model_a = XGBRegressor(**xgb_params)\n",
    "model_a.fit(X_train[features_a], y_train)\n",
    "\n",
    "# Model B: Pitching + Climate\n",
    "model_b = XGBRegressor(**xgb_params)\n",
    "model_b.fit(X_train[features_b], y_train)\n",
    "\n",
    "print(\"Both models trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQViP-uMouQ-"
   },
   "source": [
    "### Evaluation\n",
    "We compare models on the test set using three metrics:\n",
    "- **RMSE** (Root Mean Squared Error) - penalizes large errors\n",
    "- **MAE** (Mean Absolute Error) - average magnitude of errors\n",
    "- **R²** (Coefficient of Determination) - proportion of variance explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgcfWu4XpXPE",
    "outputId": "d0cb65f3-bc48-4b8e-fdf6-539d93ed12a6"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test_subset, y_test, name):\n",
    "    \"\"\"Evaluate a model and return metrics dict.\"\"\"\n",
    "    preds = model.predict(X_test_subset)\n",
    "    metrics = {\n",
    "        \"Model\": name,\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, preds)),\n",
    "        \"MAE\": mean_absolute_error(y_test, preds),\n",
    "        \"R²\": r2_score(y_test, preds),\n",
    "    }\n",
    "    return metrics, preds\n",
    "\n",
    "metrics_a, preds_a = evaluate_model(model_a, X_test[features_a], y_test, \"A: Pitching Only\")\n",
    "metrics_b, preds_b = evaluate_model(model_b, X_test[features_b], y_test, \"B: Pitching + Climate\")\n",
    "\n",
    "results = pd.DataFrame([metrics_a, metrics_b]).set_index(\"Model\")\n",
    "results = results.round(4)\n",
    "\n",
    "# Calculate improvement\n",
    "rmse_improvement = (metrics_a[\"RMSE\"] - metrics_b[\"RMSE\"]) / metrics_a[\"RMSE\"] * 100\n",
    "r2_improvement = metrics_b[\"R²\"] - metrics_a[\"R²\"]\n",
    "\n",
    "print(results)\n",
    "print(f\"\\nRMSE improvement: {rmse_improvement:.2f}%\")\n",
    "print(f\"R² improvement:   {r2_improvement:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "7Zsw3U6wpcgs",
    "outputId": "2ee1488d-079d-4d73-ee5e-c3baea8d860b"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "metrics_names = [\"RMSE\", \"MAE\", \"R²\"]\n",
    "colors = [\"steelblue\", \"coral\"]\n",
    "model_names = [\"Pitching Only\", \"Pitching + Climate\"]\n",
    "\n",
    "for ax, metric in zip(axes, metrics_names):\n",
    "    values = [results.loc[\"A: Pitching Only\", metric],\n",
    "              results.loc[\"B: Pitching + Climate\", metric]]\n",
    "    bars = ax.bar(model_names, values, color=colors, edgecolor=\"black\", alpha=0.8)\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for bar, val in zip(bars, values):\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height(),\n",
    "                f\"{val:.4f}\", ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "    ax.set_title(metric, fontsize=13)\n",
    "    ax.set_ylabel(metric)\n",
    "\n",
    "    # For RMSE and MAE, lower is better. For R², higher is better.\n",
    "    if metric in [\"RMSE\", \"MAE\"]:\n",
    "        ax.set_ylim(0, max(values) * 1.2)\n",
    "    else:\n",
    "        ax.set_ylim(min(values) * 0.9, max(values) * 1.1)\n",
    "\n",
    "fig.suptitle(\"Model Comparison: Pitching Only vs. Pitching + Climate\", y=1.02, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiUv3bdHpnCb"
   },
   "source": [
    "### Feature Importance\n",
    "XGBoost's feature importance tells us which features the model relied on most. We can observe where the climate features fall in the rank of importance compared to pitching stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 604
    },
    "id": "Sr_wkcbtqHDk",
    "outputId": "d7da9cdf-4969-4fc1-dec7-0f385df26fd3"
   },
   "outputs": [],
   "source": [
    "importance = model_b.feature_importances_\n",
    "feature_names = features_b\n",
    "\n",
    "importance_df = (\n",
    "    pd.DataFrame({\"feature\": feature_names, \"importance\": importance})\n",
    "    .sort_values(\"importance\", ascending=True)\n",
    ")\n",
    "\n",
    "# Color climate features differently\n",
    "colors = [\"coral\" if f in climate_features else \"steelblue\"\n",
    "          for f in importance_df[\"feature\"]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.barh(importance_df[\"feature\"], importance_df[\"importance\"],\n",
    "        color=colors, edgecolor=\"black\", alpha=0.8)\n",
    "ax.set_xlabel(\"Feature Importance (Gain)\")\n",
    "ax.set_title(\"Model B Feature Importance\")\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=\"steelblue\", edgecolor=\"black\", label=\"Pitching Stats\"),\n",
    "                   Patch(facecolor=\"coral\", edgecolor=\"black\", label=\"Climate Features\")]\n",
    "ax.legend(handles=legend_elements, loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrP4d36YqPNO"
   },
   "source": [
    "### Prediction vs. Actual\n",
    "This scatter plot shows the predicted vs. actual ERA visualizes the model quality. Diagonal points indicate accurate predictions. We will plot model B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "_0nFnaZwqj1r",
    "outputId": "e92911d8-5bdd-4630-cc4d-a025dbd0aa11"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for ax, preds, name in zip(axes, [preds_a, preds_b],\n",
    "                            [\"A: Pitching Only\", \"B: Pitching + Climate\"]):\n",
    "    ax.scatter(y_test, preds, alpha=0.15, s=10, color=\"steelblue\")\n",
    "\n",
    "    # Perfect prediction line\n",
    "    min_val = min(y_test.min(), preds.min())\n",
    "    max_val = max(y_test.max(), preds.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val],\n",
    "            color=\"red\", linewidth=2, linestyle=\"--\", label=\"Perfect prediction\")\n",
    "\n",
    "    ax.set_xlabel(\"Actual ERA\")\n",
    "    ax.set_ylabel(\"Predicted ERA\")\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "    ax.set_xlim(0, 12)\n",
    "    ax.set_ylim(0, 12)\n",
    "\n",
    "fig.suptitle(\"Predicted vs. Actual ERA\", y=1.02, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4JCmPe6qrDi"
   },
   "source": [
    "### Residual Analysis\n",
    "We can examine the resiudals (actual - predicted) to check for bias. A good model should have residuals centered around zero with no obvious patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "id": "DvjW-H78rG40",
    "outputId": "413122ab-c08a-469e-fe44-9532a9306ad7"
   },
   "outputs": [],
   "source": [
    "residuals_a = y_test - preds_a\n",
    "residuals_b = y_test - preds_b\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "for ax, resid, name in zip(axes, [residuals_a, residuals_b],\n",
    "                            [\"A: Pitching Only\", \"B: Pitching + Climate\"]):\n",
    "    ax.hist(resid, bins=50, edgecolor=\"black\", alpha=0.7, color=\"steelblue\")\n",
    "    ax.axvline(0, color=\"red\", linewidth=2, linestyle=\"--\")\n",
    "    ax.axvline(resid.mean(), color=\"orange\", linewidth=2, linestyle=\"--\",\n",
    "               label=f\"Mean: {resid.mean():.3f}\")\n",
    "    ax.set_xlabel(\"Residual (Actual - Predicted)\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "\n",
    "fig.suptitle(\"Residual Distributions\", y=1.02, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Model A residual std: {residuals_a.std():.3f}\")\n",
    "print(f\"Model B residual std: {residuals_b.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHN_2LS1rRn4"
   },
   "source": [
    "### Learning Curve\n",
    "We can visualize a learning curve that shows if additional data would improve the model performance. We gradually train Model B on increasing segments of training data and plot both training and validation error. A decreasing validation curve at 100% of training data then the model would benifit form more observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656
    },
    "id": "Yg1Q2_BdrW3n",
    "outputId": "bd00d910-6d23-40a5-8a3c-81bed3161034"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    XGBRegressor(**xgb_params),\n",
    "    X_train[features_b],\n",
    "    y_train,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Convert negative RMSE to positive\n",
    "train_rmse = -train_scores.mean(axis=1)\n",
    "val_rmse = -val_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "val_std = val_scores.std(axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax.plot(train_sizes, train_rmse, \"o-\", color=\"steelblue\", label=\"Training RMSE\")\n",
    "ax.fill_between(train_sizes, train_rmse - train_std, train_rmse + train_std,\n",
    "                alpha=0.1, color=\"steelblue\")\n",
    "\n",
    "ax.plot(train_sizes, val_rmse, \"o-\", color=\"coral\", label=\"Validation RMSE\")\n",
    "ax.fill_between(train_sizes, val_rmse - val_std, val_rmse + val_std,\n",
    "                alpha=0.1, color=\"coral\")\n",
    "\n",
    "ax.set_xlabel(\"Training Set Size\")\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "ax.set_title(\"Learning Curve (Model B: Pitching + Climate)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final training RMSE: {train_rmse[-1]:.4f}\")\n",
    "print(f\"Final validation RMSE: {val_rmse[-1]:.4f}\")\n",
    "print(f\"Gap: {val_rmse[-1] - train_rmse[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3FZM08at8bH"
   },
   "source": [
    "#8. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1HordswuEOh"
   },
   "source": [
    "## Evaluation Summary\n",
    "\n",
    "We trained two XGBoost regression models to predict per-game pitcher ERA across 4 MLB seasons (2022-2025):\n",
    "\n",
    "| Model | Features | RMSE | MAE | R² |\n",
    "|-------|----------|------|-----|----|\n",
    "| **A: Pitching Only** | Rolling ERA, K/9, WHIP, FIP, IP | 4.2373 | 3.2329 | -0.0121 |\n",
    "| **B: Pitching + Climate** | Above + Temperature, Humidity, Wind Speed, Elevation | 4.1991 | 3.1933 | 0.0060 |\n",
    "Adding climate features resulted in a **-0.9011% change in RMSE** and an\n",
    "**R² change of 149.5542%** compared to the pitching-only baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "y2oS_GAxuzgF",
    "outputId": "266ec54f-0a4c-4acf-a1a5-5d2baa81774c"
   },
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    \"Metric\": [\"RMSE\", \"MAE\", \"R²\"],\n",
    "    \"Pitching Only\": [\n",
    "        np.sqrt(mean_squared_error(y_test, preds_a)),\n",
    "        mean_absolute_error(y_test, preds_a),\n",
    "        r2_score(y_test, preds_a),\n",
    "    ],\n",
    "    \"Pitching + Climate\": [\n",
    "        np.sqrt(mean_squared_error(y_test, preds_b)),\n",
    "        mean_absolute_error(y_test, preds_b),\n",
    "        r2_score(y_test, preds_b),\n",
    "    ],\n",
    "}).set_index(\"Metric\")\n",
    "\n",
    "summary[\"Δ (B - A)\"] = summary[\"Pitching + Climate\"] - summary[\"Pitching Only\"]\n",
    "summary[\"% Change\"] = ((summary[\"Pitching + Climate\"] - summary[\"Pitching Only\"])\n",
    "                        / summary[\"Pitching Only\"].abs() * 100)\n",
    "\n",
    "summary.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5zJUg_zXu_SN",
    "outputId": "ab4e7ed6-1e59-4b46-e78e-3fe7b786f4e3"
   },
   "outputs": [],
   "source": [
    "# Quantify how much importance the model assigns to climate vs pitching\n",
    "pitching_importance = sum(\n",
    "    imp for feat, imp in zip(features_b, model_b.feature_importances_)\n",
    "    if feat in pitching_features\n",
    ")\n",
    "climate_importance = sum(\n",
    "    imp for feat, imp in zip(features_b, model_b.feature_importances_)\n",
    "    if feat in climate_features\n",
    ")\n",
    "\n",
    "total = pitching_importance + climate_importance\n",
    "\n",
    "print(f\"Feature importance share:\")\n",
    "print(f\"  Pitching stats: {pitching_importance / total * 100:.1f}%\")\n",
    "print(f\"  Climate features: {climate_importance / total * 100:.1f}%\")\n",
    "print(f\"\\nClimate feature breakdown:\")\n",
    "for feat, imp in sorted(\n",
    "    zip(features_b, model_b.feature_importances_),\n",
    "    key=lambda x: x[1], reverse=True\n",
    "):\n",
    "    if feat in climate_features:\n",
    "        print(f\"  {feat}: {imp / total * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2k488PGFvcun"
   },
   "source": [
    "### Question\n",
    "*Can we improve MLB pitcher ERA predictions by incorporating game-day weather conditions alongside traditional pitching statistics?*\n",
    "\n",
    "### Findings\n",
    "\n",
    "**1. Pitching history is the dominant predictor.** Rolling ERA, FIP, WHIP, and K/9 are the largest factors involved with the models prediction. This is expected as it is traditionally how professional MLB analysts have made their predictions.\n",
    "\n",
    "**2. Climate features provide modest contribution to the prediction model.** Adding temperature, humidity, wind speed, and elevation to the model changed RMSE by -0.9011% and R² by 149.5542%. Elevation contributed the most due to the Coors Field air being thinner where the air at this altitude reduced pitch movement and increase ball carry.\n",
    "\n",
    "**3. Single-game ERA is inherently noisy.** Even an increase in data and more refined features would struggle to perfectly predict a pitcher's ERA for one game. Fluctuating factors like opponent lineup, umpire strikezone discretion, defense quality introduce variance that pitching history and climate can not predict.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- **Wind direction** is neglected. Headwinds suppress ball carry while tailwinds increase it and depending on the direction of the park's outfield fence can greatly improve or worsen player performance.\n",
    "- **Rolling stats are noisy early in the season.** A pitchers first few games have limited historical data to make predictions on so the early averages will be noisy.\n",
    "- **FIP constant** was approximated at 3.17 across all four seasons by it should be computed by per season from league totals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIXWCPe60EVL"
   },
   "source": [
    "### Tools & Technologies\n",
    "\n",
    "| Category | Tools |\n",
    "|----------|-------|\n",
    "| **Language** | Python 3.10+ |\n",
    "| **ML** | XGBoost, scikit-learn |\n",
    "| **Data** | pandas, NumPy |\n",
    "| **Visualization** | matplotlib, seaborn |\n",
    "| **Data Sources** | MLB Stats API, Open-Meteo Archive API |\n",
    "| **Statistical Testing** | SciPy (Welch's t-test), statsmodels (power analysis) |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
